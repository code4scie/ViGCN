{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001d95d2d1a7451faa49ae37f7b11cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab71bfd518d2489394c8a23b163586ec",
              "IPY_MODEL_ebdc4496bd2c455cb5807dbdabdacd99",
              "IPY_MODEL_982f6a217e304dd890178d575d99c09a"
            ],
            "layout": "IPY_MODEL_7dc38d6137944ceaa461935e8b2aec1f"
          }
        },
        "ab71bfd518d2489394c8a23b163586ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cac0919833d44c291746f5b2fe39454",
            "placeholder": "​",
            "style": "IPY_MODEL_c87d273123684f64b37b3ed46fe63abc",
            "value": "Downloading: 100%"
          }
        },
        "ebdc4496bd2c455cb5807dbdabdacd99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e3a5e758564e5daa617d4ce9d6f48d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dae2d99c35b9497aa8d414a352002da5",
            "value": 231508
          }
        },
        "982f6a217e304dd890178d575d99c09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf1873674746451b88e8c434b58d4b0a",
            "placeholder": "​",
            "style": "IPY_MODEL_bde25c83db2b4f6ba555228cc410ef83",
            "value": " 226k/226k [00:00&lt;00:00, 674kB/s]"
          }
        },
        "7dc38d6137944ceaa461935e8b2aec1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cac0919833d44c291746f5b2fe39454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87d273123684f64b37b3ed46fe63abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e3a5e758564e5daa617d4ce9d6f48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae2d99c35b9497aa8d414a352002da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf1873674746451b88e8c434b58d4b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bde25c83db2b4f6ba555228cc410ef83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "781ac025ac5d41a3b9949911350d1400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c1e46161d904ce1b68ad761536003ea",
              "IPY_MODEL_da0bf5684b194868bd45133f38842a8f",
              "IPY_MODEL_312836a733974456a08ac28262ed199a"
            ],
            "layout": "IPY_MODEL_4ea560c49cfa43b1a6ef4d501202228a"
          }
        },
        "3c1e46161d904ce1b68ad761536003ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_136806a0b89d48b6a50316359514ba46",
            "placeholder": "​",
            "style": "IPY_MODEL_e4328f39b9734c5f9136689191355bb1",
            "value": "Downloading: 100%"
          }
        },
        "da0bf5684b194868bd45133f38842a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242478167c62458991d6a6d6f4cc8267",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40098156f6e2435c8730b306ee692ae1",
            "value": 28
          }
        },
        "312836a733974456a08ac28262ed199a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2005d6e259e745c585e3a3e8f8ba4407",
            "placeholder": "​",
            "style": "IPY_MODEL_9c560b93fc844d62bf677b64a1585b42",
            "value": " 28.0/28.0 [00:00&lt;00:00, 933B/s]"
          }
        },
        "4ea560c49cfa43b1a6ef4d501202228a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136806a0b89d48b6a50316359514ba46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4328f39b9734c5f9136689191355bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "242478167c62458991d6a6d6f4cc8267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40098156f6e2435c8730b306ee692ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2005d6e259e745c585e3a3e8f8ba4407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c560b93fc844d62bf677b64a1585b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34276306f3094401a8418db400d0480a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_577b4fd28a1c4ce388d819617b95b3e6",
              "IPY_MODEL_95b8ba33a0fc413dac5f327718d4de83",
              "IPY_MODEL_0329cb55f96948c1811e1ca0da940de3"
            ],
            "layout": "IPY_MODEL_9b8ff661344d435abaa46b2235723b2b"
          }
        },
        "577b4fd28a1c4ce388d819617b95b3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2626f79ddd0f4db1b1ce9ca94d99b240",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef02099b78843c0a71fef6e54ca5b0d",
            "value": "Downloading: 100%"
          }
        },
        "95b8ba33a0fc413dac5f327718d4de83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9683a7240f614732817001d9ce9442d2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fba9ce02f67412ea4715cbe2386e469",
            "value": 570
          }
        },
        "0329cb55f96948c1811e1ca0da940de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b612417b6d6940428b9cc388fb51ea72",
            "placeholder": "​",
            "style": "IPY_MODEL_9f19982541a840fbb498666faba655f4",
            "value": " 570/570 [00:00&lt;00:00, 6.64kB/s]"
          }
        },
        "9b8ff661344d435abaa46b2235723b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2626f79ddd0f4db1b1ce9ca94d99b240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef02099b78843c0a71fef6e54ca5b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9683a7240f614732817001d9ce9442d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fba9ce02f67412ea4715cbe2386e469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b612417b6d6940428b9cc388fb51ea72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f19982541a840fbb498666faba655f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPQ6sG80-mS5"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import spacy\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uHk8sEJeS5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ab839b-1107-48d9-e3f7-b39c01b56fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from requests import get\n",
        "from google.colab import drive,files\n",
        "drive.mount(\"/content/drive\")\n",
        "import pickle\n",
        "with open('./data/restrain.pickle','rb') as file:\n",
        "    localtrain = pickle.load(file)\n",
        "with open('./data/restest.pickle','rb') as file:\n",
        "    localtest = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "zFXuquQRegJw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8159b6b9-bef2-4333-cd1e-42bc8d30f0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import argparse\n",
        "from collections import Counter\n",
        "import re\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import logging\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from time import strftime, localtime\n",
        "from transformers import BertModel,AdamW"
      ],
      "metadata": {
        "id": "mMDJwd2vegMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ParseData(data_path):\n",
        "    with open(data_path) as infile:\n",
        "        all_data = []\n",
        "        data = json.load(infile)\n",
        "        for d in data:\n",
        "            for aspect in d['aspects']:\n",
        "                text_list = list(d['token'])\n",
        "                tok = list(d['token'])       # word token\n",
        "                length = len(tok)            # real length\n",
        "                # if args.lower == True:\n",
        "                tok = [t.lower() for t in tok]\n",
        "                tok = ' '.join(tok)\n",
        "                asp = list(aspect['term'])   # aspect\n",
        "                asp = [a.lower() for a in asp]\n",
        "                asp = ' '.join(asp)\n",
        "                label = aspect['polarity']   # label\n",
        "                pos = list(d['pos'])         # pos_tag \n",
        "                head = list(d['head'])       # head\n",
        "                deprel = list(d['deprel'])   # deprel\n",
        "                # position\n",
        "                aspect_post = [aspect['from'], aspect['to']] \n",
        "                post = [i-aspect['from'] for i in range(aspect['from'])] \\\n",
        "                       +[0 for _ in range(aspect['from'], aspect['to'])] \\\n",
        "                       +[i-aspect['to']+1 for i in range(aspect['to'], length)]\n",
        "                # aspect mask\n",
        "                if len(asp) == 0:\n",
        "                    mask = [1 for _ in range(length)]    # for rest16\n",
        "                else:\n",
        "                    mask = [0 for _ in range(aspect['from'])] \\\n",
        "                       +[1 for _ in range(aspect['from'], aspect['to'])] \\\n",
        "                       +[0 for _ in range(aspect['to'], length)]\n",
        "                \n",
        "                sample = {'text': tok, 'aspect': asp, 'pos': pos, 'post': post, 'head': head,\\\n",
        "                          'deprel': deprel, 'length': length, 'label': label, 'mask': mask, \\\n",
        "                          'aspect_post': aspect_post, 'text_list': text_list}\n",
        "                all_data.append(sample)\n",
        "\n",
        "    return all_data\n",
        "\n",
        "class Vocab(object):\n",
        "    ''' vocabulary of dataset '''\n",
        "    def __init__(self, vocab_list, add_pad, add_unk):\n",
        "        self._vocab_dict = dict()\n",
        "        self._reverse_vocab_dict = dict()\n",
        "        self._length = 0\n",
        "        if add_pad:\n",
        "            self.pad_word = '<pad>'\n",
        "            self.pad_id = self._length\n",
        "            self._length += 1\n",
        "            self._vocab_dict[self.pad_word] = self.pad_id\n",
        "        if add_unk:\n",
        "            self.unk_word = '<unk>'\n",
        "            self.unk_id = self._length\n",
        "            self._length += 1\n",
        "            self._vocab_dict[self.unk_word] = self.unk_id\n",
        "        for w in vocab_list:\n",
        "            self._vocab_dict[w] = self._length\n",
        "            self._length += 1\n",
        "        for w, i in self._vocab_dict.items():   \n",
        "            self._reverse_vocab_dict[i] = w  \n",
        "    \n",
        "    def word_to_id(self, word):  \n",
        "        if hasattr(self, 'unk_id'):\n",
        "            return self._vocab_dict.get(word, self.unk_id)\n",
        "        return self._vocab_dict[word]\n",
        "    \n",
        "    def id_to_word(self, id_):   \n",
        "        if hasattr(self, 'unk_word'):\n",
        "            return self._reverse_vocab_dict.get(id_, self.unk_word)\n",
        "        return self._reverse_vocab_dict[id_]\n",
        "    \n",
        "    def has_word(self, word):\n",
        "        return word in self._vocab_dict\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "    \n",
        "    @staticmethod\n",
        "    def load_vocab(vocab_path: str):\n",
        "        with open(vocab_path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    def save_vocab(self, vocab_path):\n",
        "        with open(vocab_path, \"wb\") as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "def softmax(x):\n",
        "    if len(x.shape) > 1:\n",
        "        # matrix\n",
        "        tmp = np.max(x, axis=1)\n",
        "        x -= tmp.reshape((x.shape[0], 1))\n",
        "        x = np.exp(x)\n",
        "        tmp = np.sum(x, axis=1)\n",
        "        x /= tmp.reshape((x.shape[0], 1))\n",
        "    else:\n",
        "        # vector\n",
        "        tmp = np.max(x)\n",
        "        x -= tmp\n",
        "        x = np.exp(x)\n",
        "        tmp = np.sum(x)\n",
        "        x /= tmp\n",
        "    return x"
      ],
      "metadata": {
        "id": "p516jY8on3Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer4BertGCN:\n",
        "    def __init__(self, max_seq_len, pretrained_bert_name):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_bert_name)\n",
        "        self.cls_token_id = self.tokenizer.cls_token_id\n",
        "        self.sep_token_id = self.tokenizer.sep_token_id\n",
        "    def tokenize(self, s):\n",
        "        return self.tokenizer.tokenize(s)\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        return self.tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "metadata": {
        "id": "nfn34ZA6pCKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnametrainres = './dataset/Restaurants_corenlp/train.json'\n",
        "fnametestres = './dataset/Restaurants_corenlp/test.json'\n",
        "tokenizer = Tokenizer4BertGCN(85, 'bert-base-uncased')"
      ],
      "metadata": {
        "id": "0KC_buLbG_VI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "001d95d2d1a7451faa49ae37f7b11cff",
            "ab71bfd518d2489394c8a23b163586ec",
            "ebdc4496bd2c455cb5807dbdabdacd99",
            "982f6a217e304dd890178d575d99c09a",
            "7dc38d6137944ceaa461935e8b2aec1f",
            "5cac0919833d44c291746f5b2fe39454",
            "c87d273123684f64b37b3ed46fe63abc",
            "36e3a5e758564e5daa617d4ce9d6f48d",
            "dae2d99c35b9497aa8d414a352002da5",
            "bf1873674746451b88e8c434b58d4b0a",
            "bde25c83db2b4f6ba555228cc410ef83",
            "781ac025ac5d41a3b9949911350d1400",
            "3c1e46161d904ce1b68ad761536003ea",
            "da0bf5684b194868bd45133f38842a8f",
            "312836a733974456a08ac28262ed199a",
            "4ea560c49cfa43b1a6ef4d501202228a",
            "136806a0b89d48b6a50316359514ba46",
            "e4328f39b9734c5f9136689191355bb1",
            "242478167c62458991d6a6d6f4cc8267",
            "40098156f6e2435c8730b306ee692ae1",
            "2005d6e259e745c585e3a3e8f8ba4407",
            "9c560b93fc844d62bf677b64a1585b42",
            "34276306f3094401a8418db400d0480a",
            "577b4fd28a1c4ce388d819617b95b3e6",
            "95b8ba33a0fc413dac5f327718d4de83",
            "0329cb55f96948c1811e1ca0da940de3",
            "9b8ff661344d435abaa46b2235723b2b",
            "2626f79ddd0f4db1b1ce9ca94d99b240",
            "5ef02099b78843c0a71fef6e54ca5b0d",
            "9683a7240f614732817001d9ce9442d2",
            "8fba9ce02f67412ea4715cbe2386e469",
            "b612417b6d6940428b9cc388fb51ea72",
            "9f19982541a840fbb498666faba655f4"
          ]
        },
        "outputId": "f3e06080-d2f3-40fc-a947-73241b6ea8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "001d95d2d1a7451faa49ae37f7b11cff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "781ac025ac5d41a3b9949911350d1400"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34276306f3094401a8418db400d0480a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class globaltrainABSAGCNDATA(Dataset):\n",
        "  def __init__(self,fname,tokenizer):\n",
        "    self.data = []\n",
        "    parse = ParseData\n",
        "    polarity_dict = {'positive':0,'negative':1,'neutral':2}\n",
        "    for obj in tqdm(parse(fname), total=len(parse(fname)), desc=\"Training examples\"):\n",
        "      polarity = polarity_dict[obj['label']]\n",
        "      text = obj['text']\n",
        "      term = obj['aspect']\n",
        "      term_start = obj['aspect_post'][0]\n",
        "      term_end = obj['aspect_post'][1]\n",
        "      text_list = obj['text_list']\n",
        "      left, term, right = text_list[: term_start], text_list[term_start: term_end], text_list[term_end: ]\n",
        "\n",
        "      #polarity score\n",
        "      senticNet = {}\n",
        "      with open('./senticnet/senticnetword.txt','r') as file:\n",
        "        fp = file\n",
        "        for line in fp:\n",
        "          line = line.strip()\n",
        "          if not line:\n",
        "            continue\n",
        "          word,sentic = line.split('\\t')\n",
        "          senticNet[word] = sentic\n",
        "        fp.close()\n",
        "      senticvalue = np.zeros(context_len)\n",
        "      for word_i,bword in enumerate(text_list):\n",
        "        if str(bword) in senticNet:\n",
        "          sentic = 1+abs(float(senticNet[str(bword)]))#abs(float(senticNet[str(btoken)]))\n",
        "        else:\n",
        "          sentic = 1\n",
        "        senticvalue[word_i] = sentic\n",
        "      senticvalue = torch.from_numpy(senticvalue)\n",
        "\n",
        "      #SRD\n",
        "      asp_avg_index = (len(left)*2+len(term)-1)/2\n",
        "      context_len = len(text_list)\n",
        "      for i in range(context_len):\n",
        "        srd = abs(i-asp_avg_index)-len(term)/2\n",
        "        if srd > 3:\n",
        "          senticvalue[i] = senticvalue[i]\n",
        "        else:\n",
        "          senticvalue[i] = senticvalue[i]+1\n",
        "      \n",
        "      \n",
        "      left_tokens, term_tokens, right_tokens = [], [], []\n",
        "      left_tok2ori_map, term_tok2ori_map, right_tok2ori_map = [], [], []\n",
        "      left_sentic, term_sentic, right_sentic = [], [], [] \n",
        "      for ori_i, w in enumerate(left):\n",
        "          for t in tokenizer.tokenize(w):\n",
        "              left_tokens.append(t)                   # * ['expand', '##able', 'highly', 'like', '##ing']\n",
        "              left_tok2ori_map.append(ori_i)          # * [0, 0, 1, 2, 2]\n",
        "              left_sentic.append(senticvalue[ori_i])\n",
        "      asp_start = len(left_tokens)  \n",
        "      offset = len(left) \n",
        "      for ori_i, w in enumerate(term):        \n",
        "          for t in tokenizer.tokenize(w):\n",
        "              term_tokens.append(t)\n",
        "              term_tok2ori_map.append(ori_i + offset)\n",
        "              term_sentic.append(senticvalue[ori_i+ offset])\n",
        "      asp_end = asp_start + len(term_tokens)\n",
        "      offset += len(term) \n",
        "      for ori_i, w in enumerate(right):\n",
        "          for t in tokenizer.tokenize(w):\n",
        "              right_tokens.append(t)\n",
        "              right_tok2ori_map.append(ori_i+offset)\n",
        "              term_sentic.append(senticvalue[ori_i+ offset])\n",
        "      while len(left_tokens) + len(right_tokens) > tokenizer.max_seq_len-2*len(term_tokens) - 3:\n",
        "          if len(left_tokens) > len(right_tokens):\n",
        "              left_tokens.pop(0)\n",
        "              left_tok2ori_map.pop(0)\n",
        "          else:\n",
        "              right_tokens.pop()\n",
        "              right_tok2ori_map.pop()\n",
        "              \n",
        "      bert_tokens = left_tokens + term_tokens + right_tokens\n",
        "      tok2ori_map = left_tok2ori_map + term_tok2ori_map + right_tok2ori_map\n",
        "      sentic_token = left_sentic + term_sentic + right_sentic\n",
        "      truncate_tok_len = len(bert_tokens)\n",
        "\n",
        "         \n",
        "      # context raw \n",
        "      context_raw_asp_ids = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(bert_tokens)+[tokenizer.sep_token_id]\n",
        "      context_raw_asp_len = len(context_raw_asp_ids)\n",
        "      paddings_raw = [0] * (tokenizer.max_seq_len - context_raw_asp_len)\n",
        "      context_raw_asp_ids += paddings_raw\n",
        "      context_raw_asp_ids = np.asarray(context_raw_asp_ids,dtype='int64')\n",
        "      #context+aspect\n",
        "      context_asp_ids = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(\n",
        "          bert_tokens)+[tokenizer.sep_token_id]+tokenizer.convert_tokens_to_ids(term_tokens)+[tokenizer.sep_token_id]\n",
        "      context_asp_len = len(context_asp_ids)\n",
        "      paddings = [0] * (tokenizer.max_seq_len - context_asp_len)\n",
        "      context_len = len(bert_tokens)\n",
        "      context_asp_seg_ids = [0] * (1 + context_len + 1) + [1] * (len(term_tokens) + 1) + paddings\n",
        "      #src_mask = [0] + [1] * context_len + [0] * (opt.max_length - context_len - 1)\n",
        "      src_mask = [0] + [1]*context_len + [0] * (85 - context_len - 1)\n",
        "      aspect_mask = [0] + [0] * asp_start + [1] * (asp_end - asp_start)\n",
        "      aspect_mask = aspect_mask + (85 - len(aspect_mask)) * [0]\n",
        "      context_asp_attention_mask = [1] * context_asp_len + paddings\n",
        "      context_asp_ids += paddings\n",
        "      #aspect bert \n",
        "      aspect_bert_indices = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(term_tokens) + [tokenizer.sep_token_id]\n",
        "      aspect_bert_indices_len = len(aspect_bert_indices)\n",
        "      paddings_abi = [0]*(tokenizer.max_seq_len-aspect_bert_indices_len)\n",
        "      aspect_bert_indices += paddings_abi\n",
        "      aspect_bert_indices = np.asarray(aspect_bert_indices,dtype='int64')\n",
        "      #to numpy\n",
        "      context_asp_ids = np.asarray(context_asp_ids, dtype='int64')\n",
        "      context_asp_seg_ids = np.asarray(context_asp_seg_ids, dtype='int64')\n",
        "      context_asp_attention_mask = np.asarray(context_asp_attention_mask, dtype='int64')\n",
        "      src_mask = np.asarray(src_mask, dtype='int64')\n",
        "      aspect_mask = np.asarray(aspect_mask,dtype='int64')\n",
        "\n",
        "      texts = context_raw_bert_indices.cpu().numpy()\n",
        "      asps = aspect_bert_indices.cpu().numpy()\n",
        "  \n",
        "      for text_i,asp_i in zip(range(len(texts)),range(len(asps))):\n",
        "        asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "        try:\n",
        "          asp_begin = np.argwhere(texts[text_i]==asps[asp_i][1])[0][0]\n",
        "          asp_avg_index = (asp_begin*2+asp_len-1)/2\n",
        "        except:\n",
        "          continue\n",
        "        for i in range(1,np.count_nonzero(texts[text_i])-1):\n",
        "          srd = abs(i-asp_avg_index) + (asp_len-1)/2\n",
        "          if srd>3:\n",
        "            adj[text_i,85] = adj[text_i,85]\n",
        "          else:\n",
        "            adj[text_i,85] = 1+adj[text_i,85]\n",
        "      #srd\n",
        "      texts = text_raw_bert_indices.cpu().numpy()\n",
        "      asps = aspect_bert_indices.cpu().numpy()\n",
        "      term_len = term_start - term_end\n",
        "      text_len = len(text_list)\n",
        "      term_avg_index = (term_start*2+term_len-1)/2\n",
        "      for i in range(0,np.count_nonzero(texts[text_i])):\n",
        "        srd = abs(tok2ori_map[i]-term_avg_index) + (term_len-1)/2\n",
        "        if srd > 3:\n",
        "          sentic_token[i] = sentic_token[i]\n",
        "        else:\n",
        "          sentic_token[i] = sentic_token[i]+1\n",
        "      \n",
        "      # pad adj\n",
        "      sentictrain = []\n",
        "      for i in range(len(localtrain)):\n",
        "        a = localtrain[i]['adj_matrix']\n",
        "        a = torch.from_numpy(a)\n",
        "        b = torch.zeros(85,1)\n",
        "        c = torch.zeros(1,86)\n",
        "        d = torch.cat((a,b),1)\n",
        "        e = torch.cat((d,c),0)\n",
        "        e[1:context_len+1,85] = sentic_token\n",
        "        e[85,1:context_len+1] = sentic_token\n",
        "        senticdata = {\n",
        "            'adj_matrix':e,\n",
        "        }\n",
        "        yuantrain.append(yuandata)\n",
        "      data = {\n",
        "          'text_bert_indices': context_asp_ids,\n",
        "          'text_raw_bert_indices':context_raw_asp_ids,\n",
        "          'aspect_bert_indices': aspect_bert_indices,\n",
        "          'bert_segments_ids': context_asp_seg_ids,\n",
        "          'attention_mask': context_asp_attention_mask,\n",
        "          'asp_start': asp_start,\n",
        "          'asp_end': asp_end,\n",
        "          'src_mask': src_mask,\n",
        "          'aspect_mask': aspect_mask,\n",
        "          'polarity': polarity,\n",
        "      }\n",
        "      self.data.append(data)\n",
        "      #self.data.update(localtrain)\n",
        "    for i in range(0,len(self.data)):\n",
        "      self.data[i].update(yuantrain[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "metadata": {
        "id": "c5iM7Lpln3G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class globaltestABSAGCNDATA(Dataset):\n",
        "  def __init__(self,fname,tokenizer):\n",
        "    self.data = []\n",
        "    parse = ParseData\n",
        "    polarity_dict = {'positive':0,'negative':1,'neutral':2}\n",
        "    for obj in tqdm(parse(fname), total=len(parse(fname)), desc=\"Training examples\"):\n",
        "      polarity = polarity_dict[obj['label']]\n",
        "      text = obj['text']\n",
        "      term = obj['aspect']\n",
        "      term_start = obj['aspect_post'][0]\n",
        "      term_end = obj['aspect_post'][1]\n",
        "      text_list = obj['text_list']\n",
        "      left, term, right = text_list[: term_start], text_list[term_start: term_end], text_list[term_end: ]\n",
        "\n",
        "      #polarity score\n",
        "      #polarity score\n",
        "      senticNet = {}\n",
        "      with open('./senticnet/senticnetword.txt','r') as file:\n",
        "        fp = file\n",
        "        for line in fp:\n",
        "          line = line.strip()\n",
        "          if not line:\n",
        "            continue\n",
        "          word,sentic = line.split('\\t')\n",
        "          senticNet[word] = sentic\n",
        "        fp.close()\n",
        "      senticvalue = np.zeros(context_len)\n",
        "      for word_i,bword in enumerate(text_list):\n",
        "        if str(bword) in senticNet:\n",
        "          sentic = 1+abs(float(senticNet[str(bword)]))#abs(float(senticNet[str(btoken)]))\n",
        "        else:\n",
        "          sentic = 1\n",
        "        senticvalue[word_i] = sentic\n",
        "      senticvalue = torch.from_numpy(senticvalue)\n",
        "\n",
        "      #SRD\n",
        "      asp_avg_index = (len(left)*2+len(term)-1)/2\n",
        "      context_len = len(text_list)\n",
        "      for i in range(context_len):\n",
        "        srd = abs(i-asp_avg_index)-len(term)/2\n",
        "        if srd > 3:\n",
        "          senticvalue[i] = senticvalue[i]\n",
        "        else:\n",
        "          senticvalue[i] = senticvalue[i]+1\n",
        "\n",
        "\n",
        "      left_tokens, term_tokens, right_tokens = [], [], []\n",
        "      left_tok2ori_map, term_tok2ori_map, right_tok2ori_map = [], [], []\n",
        "      left_sentic, term_sentic, right_sentic = [], [], [] \n",
        "      for ori_i, w in enumerate(left):\n",
        "          for t in tokenizer.tokenize(w):\n",
        "              left_tokens.append(t)                   # * ['expand', '##able', 'highly', 'like', '##ing']\n",
        "              left_tok2ori_map.append(ori_i)          # * [0, 0, 1, 2, 2]\n",
        "              left_sentic.append(senticvalue[ori_i])\n",
        "      asp_start = len(left_tokens)  \n",
        "      offset = len(left) \n",
        "      for ori_i, w in enumerate(term):        \n",
        "          for t in tokenizer.tokenize(w):\n",
        "              term_tokens.append(t)\n",
        "              term_tok2ori_map.append(ori_i + offset)\n",
        "              term_sentic.append(senticvalue[ori_i+ offset])\n",
        "      asp_end = asp_start + len(term_tokens)\n",
        "      offset += len(term) \n",
        "      for ori_i, w in enumerate(right):\n",
        "          for t in tokenizer.tokenize(w):\n",
        "              right_tokens.append(t)\n",
        "              right_tok2ori_map.append(ori_i+offset)\n",
        "              term_sentic.append(senticvalue[ori_i+ offset])\n",
        "      while len(left_tokens) + len(right_tokens) > tokenizer.max_seq_len-2*len(term_tokens) - 3:\n",
        "          if len(left_tokens) > len(right_tokens):\n",
        "              left_tokens.pop(0)\n",
        "              left_tok2ori_map.pop(0)\n",
        "          else:\n",
        "              right_tokens.pop()\n",
        "              right_tok2ori_map.pop()\n",
        "              \n",
        "      bert_tokens = left_tokens + term_tokens + right_tokens\n",
        "      tok2ori_map = left_tok2ori_map + term_tok2ori_map + right_tok2ori_map\n",
        "      sentic_token = left_sentic+term_sentic+right_sentic\n",
        "      truncate_tok_len = len(bert_tokens)\n",
        "         \n",
        "      # context raw \n",
        "      context_raw_asp_ids = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(bert_tokens)+[tokenizer.sep_token_id]\n",
        "      context_raw_asp_len = len(context_raw_asp_ids)\n",
        "      paddings_raw = [0] * (tokenizer.max_seq_len - context_raw_asp_len)\n",
        "      context_raw_asp_ids += paddings_raw\n",
        "      context_raw_asp_ids = np.asarray(context_raw_asp_ids,dtype='int64')\n",
        "      #context+aspect\n",
        "      context_asp_ids = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(\n",
        "          bert_tokens)+[tokenizer.sep_token_id]+tokenizer.convert_tokens_to_ids(term_tokens)+[tokenizer.sep_token_id]\n",
        "      context_asp_len = len(context_asp_ids)\n",
        "      paddings = [0] * (tokenizer.max_seq_len - context_asp_len)\n",
        "      context_len = len(bert_tokens)\n",
        "      context_asp_seg_ids = [0] * (1 + context_len + 1) + [1] * (len(term_tokens) + 1) + paddings\n",
        "      #src_mask = [0] + [1] * context_len + [0] * (opt.max_length - context_len - 1)\n",
        "      src_mask = [0] + [1]*context_len + [0] * (85 - context_len - 1)\n",
        "      aspect_mask = [0] + [0] * asp_start + [1] * (asp_end - asp_start)\n",
        "      aspect_mask = aspect_mask + (85 - len(aspect_mask)) * [0]\n",
        "      context_asp_attention_mask = [1] * context_asp_len + paddings\n",
        "      context_asp_ids += paddings\n",
        "      #aspect bert \n",
        "      aspect_bert_indices = [tokenizer.cls_token_id]+tokenizer.convert_tokens_to_ids(term_tokens) + [tokenizer.sep_token_id]\n",
        "      aspect_bert_indices_len = len(aspect_bert_indices)\n",
        "      paddings_abi = [0]*(tokenizer.max_seq_len-aspect_bert_indices_len)\n",
        "      aspect_bert_indices += paddings_abi\n",
        "      aspect_bert_indices = np.asarray(aspect_bert_indices,dtype='int64')\n",
        "      #to numpy\n",
        "      context_asp_ids = np.asarray(context_asp_ids, dtype='int64')\n",
        "      context_asp_seg_ids = np.asarray(context_asp_seg_ids, dtype='int64')\n",
        "      context_asp_attention_mask = np.asarray(context_asp_attention_mask, dtype='int64')\n",
        "      src_mask = np.asarray(src_mask, dtype='int64')\n",
        "      aspect_mask = np.asarray(aspect_mask,dtype='int64')\n",
        "      \n",
        "      # pad adj\n",
        "      sentictest = []\n",
        "      for i in range(len(localtest)):\n",
        "        a = localtest[i]['adj_matrix']\n",
        "        a = torch.from_numpy(a)\n",
        "        b = torch.zeros(85,1)\n",
        "        c = torch.zeros(1,86)\n",
        "        d = torch.cat((a,b),1)\n",
        "        e = torch.cat((d,c),0)\n",
        "        e[1:context_len+1,85] = senticvalue\n",
        "        e[85,1:context_len+1] = senticvalue\n",
        "        senticdata = {\n",
        "            'adj_matrix':e,\n",
        "        }\n",
        "        yuantrain.append(yuandata)\n",
        "      data = {\n",
        "          'text_bert_indices': context_asp_ids,\n",
        "          'text_raw_bert_indices':context_raw_asp_ids,\n",
        "          'aspect_bert_indices': aspect_bert_indices,\n",
        "          'bert_segments_ids': context_asp_seg_ids,\n",
        "          'attention_mask': context_asp_attention_mask,\n",
        "          'asp_start': asp_start,\n",
        "          'asp_end': asp_end,\n",
        "          'src_mask': src_mask,\n",
        "          'aspect_mask': aspect_mask,\n",
        "          'polarity': polarity,\n",
        "      }\n",
        "      self.data.append(data)\n",
        "      #self.data.update(localtrain)\n",
        "    for i in range(0,len(self.data)):\n",
        "      self.data[i].update(sentictest[i])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "metadata": {
        "id": "Rhdpc5QpzRpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "4-OLuf0G9E1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ],
      "metadata": {
        "id": "9ADRo9t0egPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class globalGCNBert(nn.Module):\n",
        "  def __init__(self,bert,opt,num_layers):\n",
        "    super(globalGCNBert,self).__init__()\n",
        "    self.bert = bert\n",
        "    self.opt = opt\n",
        "    self.layers = num_layers\n",
        "    self.mem_dim = opt.bert_dim // 2\n",
        "    self.bert_dim = opt.bert_dim\n",
        "    self.bert_drop = nn.Dropout(opt.bert_dropout) #0.3\n",
        "    self.pooled_drop = nn.Dropout(opt.bert_dropout) #0.3\n",
        "    self.gcn_drop = nn.Dropout(opt.gcn_dropout) #0.1\n",
        "    self.layernorm = LayerNorm(opt.bert_dim)\n",
        "\n",
        "    self.W = nn.ModuleList()\n",
        "    for layer in range(self.layers):\n",
        "      input_dim = self.bert_dim if layer == 0 else self.mem_dim\n",
        "      self.W.append(nn.Linear(input_dim, self.mem_dim))\n",
        "\n",
        "  def forward(self,adj,inputs):\n",
        "    text_bert_indices,text_raw_bert_indices,aspect_bert_indices,bert_segments_ids, attention_mask, asp_start, asp_end, adj_dep, src_mask, aspect_mask = inputs\n",
        "    src_mask = src_mask.unsqueeze(-2)\n",
        "      \n",
        "    sequence_output = self.bert(text_bert_indices, attention_mask=attention_mask,token_type_ids=bert_segments_ids)[0]\n",
        "    super_node = torch.mean(sequence_output,dim=1).unsqueeze(1)\n",
        "    super_node = torch.zeros_like(super_node)\n",
        "    pooled_output = self.bert(text_bert_indices, attention_mask=attention_mask,token_type_ids=bert_segments_ids)[1]\n",
        "    gcn_inputs = self.layernorm(sequence_output)\n",
        "    gcn_inputs = self.bert_drop(gcn_inputs)\n",
        "    pooled_output = self.pooled_drop(pooled_output)\n",
        "    gcn_inputs = torch.cat((gcn_inputs,super_node),1)\n",
        "    \n",
        "    texts = text_raw_bert_indices.cpu().numpy()\n",
        "    asps = aspect_bert_indices.cpu().numpy()\n",
        "\n",
        "    for text_i,asp_i in zip(range(len(texts)),range(len(asps))):\n",
        "      asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "      try:\n",
        "        asp_begin = np.argwhere(texts[text_i]==asps[asp_i][1])[0][0]\n",
        "        asp_avg_index = (asp_begin*2+asp_len-1)/2\n",
        "      except:\n",
        "        continue\n",
        "      for i in range(1,np.count_nonzero(texts[text_i])-1):\n",
        "        srd = abs(i-asp_avg_index) + (asp_len-1)/2\n",
        "        if srd>3:\n",
        "          adj[text_i,85] = adj[text_i,85]\n",
        "        else:\n",
        "          adj[text_i,85] = 1+adj[text_i,85]\n",
        "         \n",
        "    denom_dep = adj.sum(2).unsqueeze(2) + 1  \n",
        "    outputs_dep = gcn_inputs\n",
        "\n",
        "    for l in range(self.layers):\n",
        "      # ************SynGCN*************\n",
        "      Ax_dep = adj.bmm(outputs_dep)\n",
        "      AxW_dep = self.W[l](Ax_dep)\n",
        "      AxW_dep = AxW_dep / denom_dep\n",
        "      #AxW_dep = torch.mul(AxW_dep,memweight_text_raw_indices_1) if l>1 else AxW_dep\n",
        "      gAxW_dep = F.relu(AxW_dep)\n",
        "      outputs_dep = self.gcn_drop(gAxW_dep) if l < self.layers - 1 else gAxW_dep\n",
        "    return outputs_dep,pooled_output"
      ],
      "metadata": {
        "id": "rW5-_30VkBwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class globalGCNAbsaModel(nn.Module):\n",
        "  def __init__(self,bert,opt):\n",
        "    super().__init__()\n",
        "    self.opt = opt\n",
        "    self.gcn = globalGCNBert(bert,opt,opt.num_layers)\n",
        "  def forward(self,inputs):\n",
        "    text_bert_indices,text_raw_bert_indices,aspect_bert_indices,bert_segments_ids, attention_mask, asp_start, asp_end, adj_dep, src_mask, aspect_mask = inputs\n",
        "    h,pooled_output = self.gcn(adj_dep,inputs)\n",
        "    h = h[:,:85,:].to('cuda')\n",
        "\n",
        "    # avg pooling asp feature\n",
        "    asp_wn = aspect_mask.sum(dim=1).unsqueeze(-1)\n",
        "    aspect_mask = aspect_mask.unsqueeze(-1).repeat(1, 1, self.opt.bert_dim // 2) \n",
        "    outputs = (h*aspect_mask).sum(dim=1)/asp_wn\n",
        "    #return outputs,adj_dep\n",
        "    return outputs,adj_dep,pooled_output"
      ],
      "metadata": {
        "id": "MX1YF7vxpCS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class globalGCNBertClassifier(nn.Module):\n",
        "  def __init__(self,bert,opt):\n",
        "    super().__init__()\n",
        "    self.opt = opt\n",
        "    self.gcn_model = globalGCNAbsaModel(bert,opt=opt)\n",
        "    self.classifier = nn.Linear(opt.hidden_dim,opt.polarities_dim)\n",
        "  def forward(self,inputs):\n",
        "    outputs,adj_dep,pooled_output = self.gcn_model(inputs)\n",
        "    logits = self.classifier(outputs)\n",
        "    return logits,None"
      ],
      "metadata": {
        "id": "jNtNZymmpCVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "DLG--P1lAvGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "import logging\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn import metrics\n",
        "from time import strftime,localtime\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertModel,AdamW\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "def setup_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fnametrainres = './dataset/Restaurants_corenlp/train.json'\n",
        "fnametestres = './dataset/Restaurants_corenlp/test.json'\n",
        "tokenizer = Tokenizer4BertGCN(85, 'bert-base-uncased')\n",
        "trainset = globaltrainABSAGCNDATA(fnametrainres, tokenizer)\n",
        "testset = globaltestABSAGCNDATA(fnametestres, tokenizer)"
      ],
      "metadata": {
        "id": "0ZUDe3FnmUBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e2b85b-7af3-4a2d-c1aa-aa0911a1de5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training examples: 100%|██████████| 3608/3608 [13:01<00:00,  4.62it/s]\n",
            "Training examples: 100%|██████████| 1119/1119 [01:31<00:00, 12.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Instructor:\n",
        "  def __init__(self,opt):\n",
        "    self.opt = opt\n",
        "    tokenizer = Tokenizer4BertGCN(85, 'bert-base-uncased')\n",
        "    bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    #model_class = LocalGCNBertClassifier(bert,2)\n",
        "    self.model = globalGCNBertClassifier(bert,opt).to('cuda')\n",
        "    #trainset = globalABSAGCNDATA(fnametrainres, tokenizer)\n",
        "    #testset = globalABSAGCNDATAtest(fnametestres, tokenizer)\n",
        "    self.train_dataloader = DataLoader(dataset=trainset, batch_size=16, shuffle=True)\n",
        "    self.test_dataloader = DataLoader(dataset=testset, batch_size=16)\n",
        "    \n",
        "    if opt.device.type == 'cuda':\n",
        "      logger.info('cuda memory allocated: {}'.format(torch.cuda.memory_allocated(self.opt.device.index)))\n",
        "    self._print_args()\n",
        "\n",
        "  def _print_args(self):\n",
        "    n_trainable_params, n_nontrainable_params = 0, 0\n",
        "    for p in self.model.parameters():\n",
        "      n_params = torch.prod(torch.tensor(p.shape))\n",
        "      if p.requires_grad:\n",
        "        n_trainable_params += n_params\n",
        "      else:\n",
        "        n_nontrainable_params += n_params\n",
        "\n",
        "    logger.info('n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))\n",
        "    logger.info('training arguments:')\n",
        "    \n",
        "    for arg in vars(self.opt):\n",
        "      logger.info('>>> {0}: {1}'.format(arg, getattr(self.opt, arg)))\n",
        "  def _reset_params(self):\n",
        "    for p in self.model.parameters():\n",
        "      if p.requires_grad:\n",
        "        if len(p.shape) > 1:\n",
        "          #self.opt.initializer(p)   # xavier_uniform_\n",
        "          torch.nn.init.xavier_uniform_(p)\n",
        "        else:\n",
        "          stdv = 1. / (p.shape[0]**0.5)\n",
        "          torch.nn.init.uniform_(p, a=-stdv, b=stdv)\n",
        "  def get_bert_optimizer(self,model):\n",
        "    no_decay = ['bias','LayerNorm.weight']\n",
        "    diff_part = [\"bert.embeddings\",\"bert.encoder\"]\n",
        "    logger.info(\"bert learning rate on\")\n",
        "    #quan zhong shuai jian: weight_decay,guo ni he \n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay': self.opt.weight_decay},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(\n",
        "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.opt.bert_lr, eps=self.opt.adam_epsilon)\n",
        "    return optimizer\n",
        "\n",
        "  def _train(self,criterion,optimizer,max_test_acc_overall=0):\n",
        "    max_test_acc = 0\n",
        "    max_f1 = 0\n",
        "    global_step = 0\n",
        "    model_path = ''\n",
        "    for epoch in range(self.opt.num_epoch):\n",
        "      logger.info('>' * 60)\n",
        "      logger.info('epoch: {}'.format(epoch))\n",
        "      n_correct, n_total = 0, 0\n",
        "      for i_batch, sample_batched in enumerate(self.train_dataloader):\n",
        "        global_step += 1\n",
        "        # switch model to training mode, clear gradient accumulators\n",
        "        self.model.train()\n",
        "        optimizer.zero_grad()\n",
        "        inputs = [sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
        "        outputs, penal = self.model(inputs)\n",
        "        targets = sample_batched['polarity'].to(self.opt.device)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if global_step % self.opt.log_step == 0:\n",
        "          n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
        "          n_total += len(outputs)\n",
        "          train_acc = n_correct / n_total\n",
        "          test_acc, f1 = self._evaluate()\n",
        "          if test_acc > max_test_acc:\n",
        "            max_test_acc = test_acc\n",
        "            if test_acc > max_test_acc_overall:\n",
        "              if not os.path.exists('./state_dict'):\n",
        "                os.mkdir('./state_dict')\n",
        "              model_path = './state_dict/{}_{}_acc_{:.4f}_f1_{:.4f}'.format(\"vigcn\", \"restaurants\", test_acc, f1)\n",
        "              self.best_model = copy.deepcopy(self.model)\n",
        "              logger.info('>> saved: {}'.format(model_path))\n",
        "          if f1 > max_f1:\n",
        "            max_f1 = f1\n",
        "          logger.info('loss: {:.4f}, acc: {:.4f}, test_acc: {:.4f}, f1: {:.4f}'.format(loss.item(), train_acc, test_acc, f1))\n",
        "    return max_test_acc, max_f1, model_path\n",
        "  def _evaluate(self, show_results=False):\n",
        "    #switch model to evaluation mode\n",
        "    self.model.eval()\n",
        "    n_test_correct, n_test_total = 0, 0\n",
        "    targets_all, outputs_all = None, None\n",
        "    with torch.no_grad():\n",
        "      for batch, sample_batched in enumerate(self.test_dataloader):\n",
        "        inputs = [sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
        "        targets = sample_batched['polarity'].to(self.opt.device)\n",
        "        outputs, penal = self.model(inputs)\n",
        "        n_test_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
        "        n_test_total += len(outputs)\n",
        "        targets_all = torch.cat((targets_all, targets), dim=0) if targets_all is not None else targets\n",
        "        outputs_all = torch.cat((outputs_all, outputs), dim=0) if outputs_all is not None else outputs\n",
        "    test_acc = n_test_correct / n_test_total\n",
        "    f1 = metrics.f1_score(targets_all.cpu(), torch.argmax(outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
        "\n",
        "    labels = targets_all.data.cpu()\n",
        "    predic = torch.argmax(outputs_all, -1).cpu()\n",
        "    if show_results:\n",
        "      report = metrics.classification_report(labels, predic, digits=4)\n",
        "      confusion = metrics.confusion_matrix(labels, predic)\n",
        "      return report, confusion, test_acc, f1\n",
        "\n",
        "    return test_acc, f1\n",
        "  \n",
        "  def _test(self):\n",
        "    self.model = self.best_model\n",
        "    self.model.eval()\n",
        "    test_report, test_confusion, acc, f1 = self._evaluate(show_results=True)\n",
        "    logger.info(\"Precision, Recall and F1-Score...\")\n",
        "    logger.info(test_report)\n",
        "    logger.info(\"Confusion Matrix...\")\n",
        "    logger.info(test_confusion)\n",
        "  \n",
        "  def run(self):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = self.get_bert_optimizer(self.model)\n",
        "    max_test_acc_overall = 0\n",
        "    max_f1_overall = 0\n",
        "    #if 'bert' not in self.opt.model_name:\n",
        "        #self._reset_params()\n",
        "    max_test_acc, max_f1, model_path = self._train(criterion, optimizer, max_test_acc_overall)\n",
        "    logger.info('max_test_acc: {0}, max_f1: {1}'.format(max_test_acc, max_f1))\n",
        "    max_test_acc_overall = max(max_test_acc, max_test_acc_overall)\n",
        "    max_f1_overall = max(max_f1, max_f1_overall)\n",
        "    torch.save(self.best_model.state_dict(), model_path)\n",
        "    logger.info('>> saved: {}'.format(model_path))\n",
        "    logger.info('#' * 60)\n",
        "    logger.info('max_test_acc_overall:{}'.format(max_test_acc_overall))\n",
        "    logger.info('max_f1_overall:{}'.format(max_f1_overall))\n",
        "    self._test()\n"
      ],
      "metadata": {
        "id": "Ip6OT4LKisy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_colses = ['text_bert_indices','text_raw_bert_indices','aspect_bert_indices','bert_segments_ids', 'attention_mask', 'asp_start', 'asp_end', 'adj_matrix', 'src_mask', 'aspect_mask']"
      ],
      "metadata": {
        "id": "gQvataLNQ7e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initializers = {\n",
        "        'xavier_uniform_': torch.nn.init.xavier_uniform_,\n",
        "        'xavier_normal_': torch.nn.init.xavier_normal_,\n",
        "        'orthogonal_': torch.nn.init.orthogonal_,\n",
        "}\n",
        "optimizers = {\n",
        "        'adadelta': torch.optim.Adadelta,\n",
        "        'adagrad': torch.optim.Adagrad, \n",
        "        'adam': torch.optim.Adam,\n",
        "        'adamax': torch.optim.Adamax, \n",
        "        'asgd': torch.optim.ASGD,\n",
        "        'rmsprop': torch.optim.RMSprop,\n",
        "        'sgd': torch.optim.SGD,\n",
        "}\n",
        "   "
      ],
      "metadata": {
        "id": "EhQQFgDLpCYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--model_name', default='bert', type=str)\n",
        "#parser.add_argument('--dataset', default='laptop', type=str, help=', '.join(dataset_files.keys()))\n",
        "parser.add_argument('--optimizer', default='adam', type=str, help=', '.join(optimizers.keys()))\n",
        "parser.add_argument('--initializer', default='xavier_uniform_', type=str, help=', '.join(initializers.keys()))\n",
        "parser.add_argument('--learning_rate', default=0.002, type=float)\n",
        "parser.add_argument('--l2reg', default=1e-4, type=float)\n",
        "parser.add_argument('--num_epoch', default=15, type=int)\n",
        "parser.add_argument('--batch_size', default=16, type=int)\n",
        "parser.add_argument('--log_step', default=5, type=int)\n",
        "parser.add_argument('--embed_dim', default=300, type=int)\n",
        "parser.add_argument('--post_dim', type=int, default=30, help='Position embedding dimension.')\n",
        "parser.add_argument('--pos_dim', type=int, default=30, help='Pos embedding dimension.')\n",
        "parser.add_argument('--hidden_dim', type=int, default=384, help='GCN mem dim.')#50 #768\n",
        "parser.add_argument('--num_layers', type=int, default=2, help='Num of GCN layers.')\n",
        "parser.add_argument('--polarities_dim', default=3, type=int, help='3')\n",
        "\n",
        "parser.add_argument('--input_dropout', type=float, default=0.7, help='Input dropout rate.')\n",
        "parser.add_argument('--gcn_dropout', type=float, default=0.1, help='GCN layer dropout rate.')\n",
        "parser.add_argument('--lower', default=True, help='Lowercase all words.')\n",
        "parser.add_argument('--direct', default=False, help='directed graph or undirected graph')\n",
        "parser.add_argument('--loop', default=True)\n",
        "\n",
        "parser.add_argument('--bidirect', default=True, help='Do use bi-RNN layer.')\n",
        "parser.add_argument('--rnn_hidden', type=int, default=50, help='RNN hidden state size.')\n",
        "parser.add_argument('--rnn_layers', type=int, default=1, help='Number of RNN layers.')\n",
        "parser.add_argument('--rnn_dropout', type=float, default=0.1, help='RNN dropout rate.')\n",
        "\n",
        "parser.add_argument('--attention_heads', default=1, type=int, help='number of multi-attention heads')\n",
        "parser.add_argument('--max_length', default=85, type=int)\n",
        "parser.add_argument('--device', default=None, type=str, help='cpu, cuda')\n",
        "parser.add_argument('--seed', default=1000, type=int) #0\n",
        "parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "parser.add_argument('--vocab_dir', type=str, default='./dataset/Restaurants_corenlp')\n",
        "parser.add_argument('--pad_id', default=0, type=int)\n",
        "parser.add_argument('--parseadj', default=False, action='store_true', help='dependency probability')\n",
        "parser.add_argument('--parsehead', default=False, action='store_true', help='dependency tree')\n",
        "parser.add_argument('--cuda', default='0', type=str)\n",
        "parser.add_argument('--losstype', default=None, type=str, help=\"['doubleloss', 'orthogonalloss', 'differentiatedloss']\")\n",
        "parser.add_argument('--alpha', default=0.4, type=float) #0.25\n",
        "parser.add_argument('--beta', default=0.3, type=float)  #0.25\n",
        "\n",
        "# * bert\n",
        "parser.add_argument('--pretrained_bert_name', default='bert-base-uncased', type=str)\n",
        "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "parser.add_argument('--bert_dim', type=int, default=768)\n",
        "parser.add_argument('--bert_dropout', type=float, default=0.3, help='BERT dropout rate.')\n",
        "parser.add_argument('--diff_lr', default=False, action='store_true')\n",
        "parser.add_argument('--bert_lr', default=2e-5, type=float)\n",
        "opt = parser.parse_args(args=[])"
      ],
      "metadata": {
        "id": "mrQHEbsZiuQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt.inputs_cols = inputs_colses\n",
        "opt.initializer = initializers[opt.initializer]\n",
        "opt.optimizer = optimizers[opt.optimizer]\n",
        "opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if opt.device is None else torch.device(opt.device)\n",
        "setup_seed(opt.seed)"
      ],
      "metadata": {
        "id": "4q56bKUvh9nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./log'):\n",
        "        os.makedirs('./log', mode=0o777)\n",
        "log_file = '{}-{}-{}.log'.format(\"vigcn\",  \"restaurants\", strftime(\"%Y-%m-%d_%H:%M:%S\", localtime()))\n",
        "logger.addHandler(logging.FileHandler(\"%s/%s\" % ('./log', log_file)))"
      ],
      "metadata": {
        "id": "rm-JljQih9ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ins = Instructor(opt)\n",
        "ins.run()"
      ],
      "metadata": {
        "id": "uNr6qJg30TVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
